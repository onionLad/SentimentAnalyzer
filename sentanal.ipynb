{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentanal\n",
    "A sentiment analysis classifier. This program reads in a set of text passages labeled either positive (1) or negative (0). It then trains a classifier that can determine if unlabeled texts contain positive or negative messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "data  = pd.read_csv(\"data.csv\")\n",
    "train = data.loc[:79]\n",
    "test  = data.loc[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage cleaner\n",
    "def cleanPassage(passage):\n",
    "    new_passage = []\n",
    "    for word in passage.split(' '):\n",
    "        word = word.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").lower()\n",
    "        if word == 'going': word = 'go'\n",
    "        if word == 'you\\'re': word = 'you'\n",
    "        new_passage.append(word)\n",
    "    return new_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building frequency dictionaries\n",
    "pos_freq = {}\n",
    "neg_freq = {}\n",
    "for idx, row in data.iterrows():\n",
    "\n",
    "    # Cleaning the passage\n",
    "    passage = row['passage']\n",
    "    new_passage = cleanPassage(passage)\n",
    "\n",
    "    # Adding words to the frequency dictionaries\n",
    "    if row['label'] == 0:\n",
    "        for word in new_passage:\n",
    "            if word not in neg_freq:\n",
    "                neg_freq[word] = 1\n",
    "            else:\n",
    "                neg_freq[word] += 1\n",
    "            if word not in pos_freq:\n",
    "                pos_freq[word] = 0\n",
    "    else:\n",
    "        for word in new_passage:\n",
    "            if word not in pos_freq:\n",
    "                pos_freq[word] = 1\n",
    "            else:\n",
    "                pos_freq[word] += 1\n",
    "            if word not in neg_freq:\n",
    "                neg_freq[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop-word remover\n",
    "def remStopWords(passage):\n",
    "    stopWordList = ['the', 'was', 'i', 'it', 'had', 'a', 'at', 'if', 'to',\n",
    "                    'this', 'you', 'have', 'my', 'thought']\n",
    "    for word in stopWordList:\n",
    "        if word in passage: passage.remove(word)\n",
    "    return passage\n",
    "\n",
    "# Vectorizer\n",
    "def vectorize(passage):\n",
    "    pf, nf  = 0, 0\n",
    "    for word in np.unique(passage):\n",
    "        pf += pos_freq[word]\n",
    "        nf += neg_freq[word]\n",
    "    return np.array([1, pf, nf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and vectorizing training data\n",
    "train_vectors = np.zeros((len(train), 3))\n",
    "for idx, row in train.iterrows():\n",
    "    passage = cleanPassage(row['passage'])\n",
    "    passage = remStopWords(passage)\n",
    "    train_vectors[idx] = vectorize(passage)\n",
    "train_labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 - math.exp(-x))\n",
    "\n",
    "# Loss function\n",
    "def getLoss(xs, ys, thetas):\n",
    "    num_examples = len(xs)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        feature_vector = xs[i]\n",
    "        label = ys[i]\n",
    "        prediction = sigmoid(np.dot(thetas, feature_vector))\n",
    "        difference = prediction - label\n",
    "        total_loss += difference\n",
    "\n",
    "    average_loss = total_loss / num_examples\n",
    "    return average_loss\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(xs, ys, thetas):\n",
    "    num_examples = len(xs)\n",
    "    num_correct  = 0\n",
    "    for i in range(num_examples):\n",
    "        num_correct += ((sigmoid(thetas.dot(xs[i])) >= 0.5) == ys[i])\n",
    "    return num_correct / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04330515852495163\n",
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "thetas = np.array([0.5, 0.5, 0.5])\n",
    "for idx, vector in enumerate(train_vectors):\n",
    "    h = sigmoid(thetas.dot(vector))\n",
    "    gradient = (1 / len(train_vectors)) * vector * (h - train_labels[idx])\n",
    "    thetas = thetas - ALPHA * gradient\n",
    "\n",
    "    loss = abs(getLoss(train_vectors, train_labels, thetas))\n",
    "    # if loss <= 0.005:\n",
    "    #     break\n",
    "\n",
    "    acc = accuracy(train_vectors, train_labels, thetas)\n",
    "    if acc > 0.95:\n",
    "        break\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Testing the classifier\n",
    "test_vectors = np.zeros((len(test), 3))\n",
    "test = test.reset_index(drop=True)\n",
    "for idx, row in test.iterrows():\n",
    "    passage = cleanPassage(row['passage'])\n",
    "    passage = remStopWords(passage)\n",
    "    test_vectors[idx] = vectorize(passage)\n",
    "test_labels = test['label']\n",
    "\n",
    "print(f\"Accuracy: {accuracy(test_vectors, test_labels, thetas)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
